{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_initialize_variables' from 'keras.src.backend' (c:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, Model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m relu, tanh\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model\n",
      "File \u001b[1;32mc:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\_v2\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\api\\_v2\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_initialize_variables' from 'keras.src.backend' (c:\\Users\\Mahmoud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.activations import relu, tanh\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Tensorflow\", tf.__version__)\n",
    "from packaging.version import parse as parse_version\n",
    "# assert parse_version(tf.__version__) < parse_version(\"2.4.0\"), \\\n",
    "#     f\"Please install TensorFlow version 2.3.1 or older. Your current version is {tf.__version__}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to get GPU power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pipeline\n",
    "The input pipeline is adapted from https://www.tensorflow.org/tutorials/generative/cyclegan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (256, 256, 3)\n",
    "IMG_HEIGHT = image_shape[0]\n",
    "IMG_WIDTH = image_shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "BUFFER_SIZE = 1000\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "dataset, ds_info = tfds.load('cycle_gan/horse2zebra', with_info=True,  as_supervised=True)\n",
    "train_horses, train_zebras = dataset['trainA'], dataset['trainB']\n",
    "test_horses, test_zebras = dataset['testA'], dataset['testB']\n",
    "\n",
    "def random_crop(image):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286 x 286 x 3\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256 x 256 x 3\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_image_train(image, label):\n",
    "    image = random_jitter(image)\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image, label):\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "train_horses = train_horses.map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "\n",
    "train_zebras = train_zebras.map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "\n",
    "test_horses = test_horses.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(4).repeat()\n",
    "\n",
    "test_zebras = test_zebras.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(4).repeat()\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((train_horses, train_zebras))\n",
    "test_dataset = tf.data.Dataset.zip((test_horses, test_zebras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    #Initializes the class with an __init__ method which takes input_shape as a parameter.\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        # Defines two input layers image_A and image_B with the given input_shape.\n",
    "        image_A = layers.Input(shape=input_shape)\n",
    "        image_B = layers.Input(shape=input_shape)\n",
    "\n",
    "        # discriminator\n",
    "        #Builds discriminator networks (discriminator_A and discriminator_B) using the build_discriminator method.\n",
    "        self.discriminator_B = self.build_discriminator()\n",
    "        self.discriminator_A = self.build_discriminator()\n",
    "        self.discriminator_B.trainable = False\n",
    "        self.discriminator_A.trainable = False\n",
    "        self.optimizer_discriminator_B = Adam(2e-4, 0.5)\n",
    "        self.optimizer_discriminator_A = Adam(2e-4, 0.5)\n",
    "        \n",
    "        self.generator_AB = self.build_generator()\n",
    "        self.generator_BA = self.build_generator()\n",
    "        \n",
    "        # forward\n",
    "        fake_B = self.generator_AB(image_A)\n",
    "        discriminator_B_output = self.discriminator_B(fake_B)\n",
    "        reconstructed_A = self.generator_BA(fake_B)\n",
    "        \n",
    "        # backward\n",
    "        fake_A = self.generator_BA(image_B)\n",
    "        discriminator_A_output = self.discriminator_A(fake_A)\n",
    "        reconstructed_B = self.generator_AB(fake_A)\n",
    "        \n",
    "        # identity\n",
    "        # Generates identity mappings for images A and B using respective generators.\n",
    "        identity_A = self.generator_AB(image_A)\n",
    "        identity_B = self.generator_BA(image_B)\n",
    "        # Defines the CycleGAN model with inputs as image_A and image_B, and outputs as discriminator outputs, reconstructed images, and identity mappings.\n",
    "        self.model = Model(inputs=[image_A, image_B],\n",
    "                           outputs=[discriminator_B_output, discriminator_A_output,\n",
    "                                    reconstructed_A, reconstructed_B,\n",
    "                                    identity_A, identity_B\n",
    "                                    ])\n",
    "        \n",
    "        # build generator pipeline with frozen discriminator\n",
    "        self.LAMBDA = 10\n",
    "        self.LAMBDA_ID = 2\n",
    "        # Compiles the model with multiple losses for discriminators and generators, and sets the Adam optimizer with specified learning rate and beta_1 parameters.\n",
    "\n",
    "        self.model.compile(loss = ['mse','mse', 'mae','mae', 'mae','mae'],\n",
    "                           optimizer = Adam(2e-4, 0.5),\n",
    "                           loss_weights=[1, 1, \n",
    "                                         self.LAMBDA, self.LAMBDA,\n",
    "                                         self.LAMBDA_ID, self.LAMBDA_ID])\n",
    "        self.discriminator_B.trainable = True\n",
    "        self.discriminator_A.trainable = True\n",
    "        self.mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        self.patch_size = self.discriminator_B.output.shape[1]\n",
    "        \n",
    "    def mse_loss(self, y_true, y_pred):\n",
    "        \n",
    "        loss = self.mse(y_true, y_pred)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def downsample(self, channels, kernels, strides=2, norm=True, activation=True, dropout=False):\n",
    "        initializer = tf.random_normal_initializer(0., 0.02)\n",
    "        block = tf.keras.Sequential()\n",
    "        block.add(layers.Conv2D(channels, kernels, strides=strides, padding='same', \n",
    "                                use_bias=False, kernel_initializer=initializer))\n",
    "\n",
    "        if norm:\n",
    "            block.add(InstanceNormalization())              \n",
    "        if activation:\n",
    "            block.add(layers.LeakyReLU(0.2)) \n",
    "        if dropout:\n",
    "            block.add(layers.Dropout(0.5))\n",
    "\n",
    "        return block\n",
    "\n",
    "    def upsample(self, channels, kernels, strides=1, norm=True, activation=True, dropout=False):\n",
    "        initializer = tf.random_normal_initializer(0., 0.02)\n",
    "        block = tf.keras.Sequential()\n",
    "        block.add(layers.UpSampling2D((2,2)))\n",
    "        block.add(layers.Conv2D(channels, kernels, strides=strides, padding='same', \n",
    "                                use_bias=False, kernel_initializer=initializer))\n",
    "\n",
    "        if norm:\n",
    "            block.add(InstanceNormalization())              \n",
    "        if activation:\n",
    "            block.add(layers.LeakyReLU(0.2)) \n",
    "        if dropout:\n",
    "            block.add(layers.Dropout(0.5))\n",
    "\n",
    "        return block\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        DIM = 64\n",
    "\n",
    "        input_image = layers.Input(shape=image_shape)\n",
    "        down1 = self.downsample(DIM, 4, norm=False)(input_image) # 128, DIM\n",
    "        down2 = self.downsample(2*DIM, 4)(down1) # 64, 2*DIM\n",
    "        down3 = self.downsample(4*DIM, 4)(down2) # 32, 4*DIM\n",
    "        down4 = self.downsample(4*DIM, 4)(down3) # 16, 4*DIM\n",
    "        down5 = self.downsample(4*DIM, 4)(down4) # 8, 4*DIM\n",
    "        down6 = self.downsample(4*DIM, 4)(down5) # 4, 4*DIM\n",
    "        down7 = self.downsample(4*DIM, 4)(down6) # 2, 4*DIM\n",
    "\n",
    "\n",
    "        up6 = self.upsample(4*DIM, 4, dropout=True)(down7) # 4,4*DIM\n",
    "        concat6 = layers.Concatenate()([up6, down6])   \n",
    "\n",
    "        up5 = self.upsample(4*DIM, 4, dropout=True)(concat6) \n",
    "        concat5 = layers.Concatenate()([up5, down5]) \n",
    "\n",
    "        up4 = self.upsample(4*DIM, 4, dropout=True)(concat5) \n",
    "        concat4 = layers.Concatenate()([up4, down4]) \n",
    "\n",
    "        up3 = self.upsample(4*DIM, 4)(concat4) \n",
    "        concat3 = layers.Concatenate()([up3, down3]) \n",
    "\n",
    "        up2 = self.upsample(2*DIM, 4)(concat3) \n",
    "        concat2 = layers.Concatenate()([up2, down2]) \n",
    "\n",
    "        up1 = self.upsample(DIM, 4)(concat2) \n",
    "        concat1 = layers.Concatenate()([up1, down1]) \n",
    "\n",
    "        output_image = tanh(self.upsample(3, 4, norm=False, activation=False)(concat1))\n",
    "\n",
    "        return Model(input_image, output_image)         \n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        DIM = 64\n",
    "        \n",
    "        input_image = layers.Input(shape=image_shape)\n",
    "        x = self.downsample(DIM, 4, norm=False)(input_image) # 128\n",
    "        x = self.downsample(2*DIM, 4)(x) # 64\n",
    "        x = self.downsample(4*DIM, 4)(x) # 32\n",
    "        x = self.downsample(8*DIM, 4, strides=1)(x) # 29\n",
    "        output = layers.Conv2D(1, 4)(x)\n",
    "\n",
    "        return Model(input_image, output)     \n",
    "    \n",
    "    def train_discriminator(self, direction, \n",
    "                            real_images_A, \n",
    "                            real_images_B):\n",
    "        if direction=='AB':\n",
    "            generator = self.generator_AB\n",
    "            discriminator = self.discriminator_B\n",
    "            optimizer = self.optimizer_discriminator_B\n",
    "        else:\n",
    "            generator = self.generator_BA\n",
    "            discriminator = self.discriminator_A\n",
    "            optimizer = self.optimizer_discriminator_A\n",
    "            \n",
    "        real_labels = tf.ones((self.batch_size, self.patch_size, self.patch_size, 1))\n",
    "        fake_labels = tf.zeros((self.batch_size, self.patch_size, self.patch_size, 1))\n",
    "                  \n",
    "        fake_images = generator.predict(real_images_A)\n",
    "        \n",
    "        with tf.GradientTape() as gradient_tape:\n",
    "            \n",
    "            # forward pass\n",
    "            pred_fake = discriminator(fake_images)\n",
    "            pred_real = discriminator(real_images_B)\n",
    "            \n",
    "            # calculate losses\n",
    "            loss_fake = self.mse_loss(fake_labels, pred_fake)\n",
    "            loss_real = self.mse_loss(real_labels, pred_real)           \n",
    "            \n",
    "            # total loss\n",
    "            total_loss = 0.5*(loss_fake + loss_real)\n",
    "            \n",
    "            # apply gradients\n",
    "            gradients = gradient_tape.gradient(total_loss, discriminator.trainable_variables)\n",
    "            \n",
    "            optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "    def train(self, data_generator, test_data_generator, batch_size, steps, interval=100):\n",
    "        checkpoint_path = \"./checkpoints/cyclegan_horse2zebra\"\n",
    "        ckpt = tf.train.Checkpoint(gen_ab = self.generator_AB,\n",
    "                                    gen_ba = self.generator_BA)\n",
    "        ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=40)\n",
    "        real_labels = tf.ones((batch_size, self.patch_size, self.patch_size, 1))\n",
    "        self.batch_size = batch_size\n",
    "        for i in range(steps):\n",
    "            real_images_A, real_images_B = next(data_generator)\n",
    "\n",
    "            d_loss_AB = self.train_discriminator(\"AB\", real_images_A, real_images_B)\n",
    "            d_loss_BA = self.train_discriminator(\"BA\", real_images_B, real_images_A)    \n",
    "            # train generator\n",
    "            combined_loss = self.model.train_on_batch([real_images_A, real_images_B], \n",
    "                                                      [real_labels, real_labels,\n",
    "                                                       real_images_A, real_images_B,\n",
    "                                                       real_images_A, real_images_B\n",
    "                                                       ])\n",
    "            \n",
    "            \n",
    "            if i%interval == 0:\n",
    "                ckpt_save_path = ckpt_manager.save()\n",
    "                print ('Saving checkpoint for step {} at {}'.format(i,\n",
    "                                                                     ckpt_save_path))\n",
    "                msg = \"Step {}: d_loss_AB {:.4f} d_loss_AB {:.4f} g_loss_AB {:.4f} g_loss_BA {:.4f} reconstr_loss_AB {:.4f} reconstr_loss_BA {:.4f}\"\\\n",
    "                .format(i, d_loss_AB, d_loss_BA, combined_loss[0], combined_loss[1], combined_loss[2], combined_loss[3])\n",
    "                print(msg)\n",
    "                val_images = next(test_data_generator)        \n",
    "                val_images_AB = self.generator_AB.predict(val_images[0])\n",
    "                val_images_BA = self.generator_BA.predict(val_images[1])\n",
    "                self.plot_images(val_images, val_images_AB, val_images_BA)\n",
    "            \n",
    "    def plot_images(self, real_images, images_AB, images_BA):   \n",
    "        grid_row = min(images_AB.shape[0], 4)\n",
    "        grid_col = 4\n",
    "        f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*6, grid_row*6))\n",
    "\n",
    "        for row in range(grid_row):\n",
    "            \n",
    "            ax = axarr if grid_row==1 else axarr[row]\n",
    "\n",
    "            ax[0].imshow((real_images[0][row]+1)/2)\n",
    "            ax[0].axis('off')\n",
    "            ax[1].imshow((images_BA[row]+1)/2)\n",
    "            ax[1].axis('off') \n",
    "            ax[2].imshow((real_images[1][row]+1)/2)\n",
    "            ax[2].axis('off') \n",
    "            ax[3].imshow((images_AB[row]+1)/2)\n",
    "            ax[3].axis('off') \n",
    "        plt.show()\n",
    "        \n",
    "    def sample_images(self, number):\n",
    "        z = tf.random.normal((number, self.z_dim))\n",
    "        images = self.generator.predict(z)\n",
    "        self.plot_images(images)\n",
    "        return images\n",
    "    \n",
    "cyclegan = CycleGAN(image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cyclegan.train(iter(train_dataset), iter(test_dataset), BATCH_SIZE, 20000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ckpt_path = \"./checkpoints/cyclegan_horse2zebra/ckpt-25\"\n",
    "ckpt = tf.train.Checkpoint(gen_ab = cyclegan.generator_AB,\n",
    "                           gen_ba = cyclegan.generator_BA).restore(ckpt_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    val_images = next(test_iterator) \n",
    "    val_images_AB = cyclegan.generator_AB.predict(val_images[0])\n",
    "    val_images_BA = cyclegan.generator_BA.predict(val_images[1])\n",
    "    cyclegan.plot_images(val_images, val_images_AB, val_images_BA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
